<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Hexo</title>
  <meta name="description" content="计算机视觉，人工智能">
<meta property="og:type" content="website">
<meta property="og:title" content="Multi-Dimensional Computer Vision Team">
<meta property="og:url" content="http://sues-vision.github.io/index.html">
<meta property="og:site_name" content="Multi-Dimensional Computer Vision Team">
<meta property="og:description" content="计算机视觉，人工智能">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Atiuo">
<meta name="twitter:card" content="summary">
  <!-- Canonical links -->
  <link rel="canonical" href="http://sues-vision.github.io/index.html">
  
    <link rel="alternate" href="/atom.xml" title="Multi-Dimensional Computer Vision Team" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/1.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 5.3.0"></head>


<body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/sues-vision" target="_blank">
          <img class="img-circle img-rotate" src="/img/avatar.png" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">多维度计算机视觉团队</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Multi-Dimensional Computer Vision Team</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shanghai, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-papers">
          <a href="/2017/12/31/03-paperlist">
            
            <span class="menu-title">论文</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/2017/12/31/02-projects">
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-reward">
          <a href="/reward">
            
            <span class="menu-title">获奖</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-patents">
          <a href="/Patents">
            
            <span class="menu-title">专利</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-graduate">
          <a href="/graduate">
            
            <span class="menu-title">毕业生去向</span>
          </a>
        </li>
        
      </ul>
      
    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/%E4%B8%89%E7%BB%B4-3D/" style="font-size: 13.75px;">三维 3D</a> <a href="/tags/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB-Action-Recognition/" style="font-size: 13px;">动作识别 Action Recognition</a> <a href="/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F-Medical-Image/" style="font-size: 13.25px;">医学图像 Medical Image</a> <a href="/tags/%E5%8D%95%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA-Single-object-Tracking/" style="font-size: 13px;">单目标跟踪 Single-object Tracking</a> <a href="/tags/%E5%90%8C%E6%AD%A5%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%9C%B0%E5%9B%BE%E7%BB%98%E5%88%B6-SLAM/" style="font-size: 13.25px;">同步定位与地图绘制 SLAM</a> <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-GNN/" style="font-size: 13px;">图神经网络 GNN</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81-CLIP/" style="font-size: 13px;">多模态 CLIP</a> <a href="/tags/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA-MOT/" style="font-size: 13.25px;">多目标跟踪 MOT</a> <a href="/tags/%E5%AD%A6%E6%9C%AF%E4%BA%A4%E6%B5%81-Academic-Activities/" style="font-size: 13px;">学术交流 Academic Activities</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88-Data-Fusion/" style="font-size: 13.25px;">数据融合 Data Fusion</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Unsupervised-Learning/" style="font-size: 13px;">无监督学习 Unsupervised Learning</a> <a href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Attention/" style="font-size: 13.75px;">注意力机制 Attention</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Object-Detection/" style="font-size: 13.5px;">目标检测 Object Detection</a> <a href="/tags/%E8%87%AA%E4%B8%BB%E8%BF%90%E5%8A%A8-ego-motion/" style="font-size: 13px;">自主运动 ego-motion</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6-Automatic-Driving/" style="font-size: 13px;">自动驾驶 Automatic Driving</a> <a href="/tags/%E8%A1%8C%E4%BA%BA%E5%88%86%E5%89%B2-Person-Segmentation/" style="font-size: 13.25px;">行人分割 Person Segmentation</a> <a href="/tags/%E8%A1%8C%E4%BA%BA%E9%87%8D%E8%AF%86%E5%88%AB-Person-re-identification/" style="font-size: 13.5px;">行人重识别 Person re-identification</a> <a href="/tags/%E8%A3%82%E7%BC%9D%E6%A3%80%E6%B5%8B-Crack-Detection/" style="font-size: 13px;">裂缝检测 Crack Detection</a> <a href="/tags/%E8%AE%BA%E6%96%87-Article/" style="font-size: 14px;">论文 Article</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">五月 2024</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">四月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/14/paper-2023-MDPI-Symmetry/" class="title">Fan L，Chen W，Jiang X Cross-Correlation Fusion Graph Convolution-Based Object Tracking，*Symmetry* 2023</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-14T05:36:20.000Z" itemprop="datePublished">2024-05-14</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/14/paper-2023-IEEE-TSMC/" class="title">Xiaoyan Jiang, J N Hwang and Z Fang, &#34;A Multiscale Coarse-to-Fine Human Pose Estimation Network With Hard Keypoint Mining&#34; in IEEE Transactions on Systems, Man, and Cybernetics:Systems, March 2024</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-14T02:25:39.000Z" itemprop="datePublished">2024-05-14</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/11/paper-2023-ictee/" class="title">Kunlun Xue, Xiaoyan Jiang, Zhichao Chen“A SLAM Method Based on ORB-SLAM3 Which Mixed GNSS Data” International Conference on Information Technologies and Electrical Engineering</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-11T07:52:27.000Z" itemprop="datePublished">2024-05-11</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/07/paper-2023-IEEE/" class="title">Wenwen Zheng,Xiaoyan Jiang, Zhijun Fang etc, &#34;TV-Net:A Structure-Level Feature Fusion Network Based on Tensor Voting for Road Crack Segmentation&#34; in IEEE Transactions on Intelligent Transportation Systems, June 2024</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-07T07:51:43.000Z" itemprop="datePublished">2024-05-07</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/06/paper-2023-PR/" class="title">Baihong Han, Xiaoyan Jiang, Zhijun Fang, Hamido Fujita, Yongbin Gao,F-SCP:An automatic prompt generation method for specific classes based on visual language pre-training models,*Pattern Recognition*,2024</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-06T09:43:16.000Z" itemprop="datePublished">2024-05-06</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  <main class="main" role="main">
  
  <div class="content article-list">
    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/31/01-tutor/">导师简介</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p style="text-align:center;">  
    <img src="https://sues-vision.github.io/2017/12/31/01-tutor/3.jpg" style="display: block; margin: auto; width:150px;">  
</p>



<hr>

<p><span style="font-size:20px;"><em>姜晓燕，副教授、硕导，博士毕业于耶拿大学（德国）计算机科学专业，现就职于上海工程技术大学电子与电气工程学院计算机系。</em></span></p>
<hr>
<span style="font-size:20px;">研究课题为计算机视觉、深度学习，应用领域包括视频监控、医疗辅助分析、工业检测、场景理解、智能交通等。在计算机视觉、人工智能领域发表论文50余篇，其中SCI/EI 40余篇，包括Trans. SMC, Trans. ITS, Pattern Recognition, Knowledge-Based Systems (KBS), SPIC, ICIP, ICONIP, ICME等。为多个顶级国际会议与期刊的评审。 ICPCSEE2019、IEA/AIE2023的项目委员会成员、在CiSE2023，IWITC2021，ICFTIC2019国际会议做主旨报告。担任Applied Intelligence期刊副主编一职。</span>
<hr>
<span style="font-size:20px;">曾获德国DAAD、中国政府奖学金CSC资助。上海工程技术大学青年五四奖章集体成员、上海市长宁区第四轮创新团队–智能视觉感知与信息处理创新团队核心成员、上海工程技术大学电子电气工程学院优秀教师。主持/参与国家自然科学基金青年项目、民航重点、面上、上海市教委项目、上海市科委重点项目、上海飞机制造有限公司项目等多项。申请发明专利八项，实用新型专利五项、软著多项。</span>
<hr>
<span style="font-size:20px;">现为电子与电气工程学院多维度人工智能科研团队负责人，团队注重科技研发的同时，积极推进人工智能技术的产业化。与各行业企业开展产学研合作，以5G + AI为未来模式，已在智能交通、三维场景建模、视频监控、瑕疵巡检、智慧医疗等方面取得多项成果，并应用到实际场景中。研究涵盖计算机视觉领域的多个课题：多目标跟踪、域自适应行人重识别、语义分割、视觉SLAM。所负责的项目应用到的领域：智能交通、视频监控、大型客机表面喷漆瑕疵检测、工业缺陷检测、胃癌淋巴结转移检测、眼震疾病诊断、心脏周期分析等。</span>
<hr>

<p><span style="font-size:20px;"><strong>团队以学生发展为中心，打牢从传统视觉算法到深度学习及大模型相关的关键知识与理论，结合实际场景，培养学生独立思考，发现问题和解决问题的能力。目标为激发大家持续终身学习的内驱力，最终团队得到成长和发展！<br>如果你对自我有要求，对科学好奇，愿意为解决问题而努力，那本团队适合你，欢迎加入！</strong></span></p>
<hr>


<p>导师授课内容：计算机视觉、机器学习、数字图像处理、面向对象程序设计<br>导师办公室：上海工程技术大学现代交通楼7823</p>
<p><a target="_blank" rel="noopener" href="https://scholar.google.com/citations?hl=zh-CN&user=pKnD8WcAAAAJ">谷歌学术</a><br>邮箱：<a href="mailto:&#x78;&#105;&#97;&#111;&#121;&#97;&#110;&#x2e;&#x6a;&#x69;&#x61;&#110;&#x67;&#x40;&#x73;&#x75;&#x65;&#115;&#x2e;&#x65;&#100;&#x75;&#x2e;&#99;&#x6e;">&#x78;&#105;&#97;&#111;&#121;&#97;&#110;&#x2e;&#x6a;&#x69;&#x61;&#110;&#x67;&#x40;&#x73;&#x75;&#x65;&#115;&#x2e;&#x65;&#100;&#x75;&#x2e;&#99;&#x6e;</a>.</p>
<img src="/2017/12/31/01-tutor/4.jpg" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2017/12/31/01-tutor/" class="article-date">
	  <time datetime="2017-12-31T07:45:40.000Z" itemprop="datePublished">12月 31</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/Team/">Team</a>
  </span>

    

    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2017/12/31/01-tutor/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/05/14/paper-2023-MDPI-Symmetry/">Fan L，Chen W，Jiang X Cross-Correlation Fusion Graph Convolution-Based Object Tracking，*Symmetry* 2023</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>团队2019级研究生范柳伊同学的论文“Cross-Correlation Fusion Graph Convolution-Based Object Tracking”被期刊“Multidisciplinary Digital Publishing Institute Symmetry”录用，祝贺！</p>
<p>Abstract:<br>Most popular graph attention networks treat pixels of a feature map as individual nodes, which makes the feature embedding extracted by the graph convolution lack the integrity of the object. Moreover, matching between a template graph and a search graph using only part-level information usually causes tracking errors, especially in occlusion and similarity situations. To address these problems, we propose a novel end-to-end graph attention tracking framework that has high symmetry, combining traditional cross-correlation operations directly. By utilizing cross-correlation operations, we effectively compensate for the dispersion of graph nodes and enhance the representation of features. Additionally, our graph attention fusion model performs both part-to-part matching and global matching, allowing for more accurate information embedding in the template and search regions. Furthermore, we optimize the information embedding between the template and search branches to achieve better single-object tracking results, particularly in occlusion and similarity scenarios. The flexibility of graph nodes and the comprehensiveness of information embedding have brought significant performance improvements in our framework. Extensive experiments on three challenging public datasets (LaSOT, GOT-10k, and VOT2016) show that our tracker outperforms other state-of-the-art trackers.</p>
<p><strong>Download:</strong> <a target="_blank" rel="noopener" href="https://www.mdpi.com/2073-8994/15/3/771">[官方链接]</a></p>
<p><strong>Keywords:</strong>  symmetry; single-object tracking; graph attention network; Siamese networks; cross-correlation; feature fusion</p>
<p><strong>Photos:</strong> </p>
<img src="/2024/05/14/paper-2023-MDPI-Symmetry/MDPI.PNG" class>
<img src="/2024/05/14/paper-2023-MDPI-Symmetry/MDPI2.PNG" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2024/05/14/paper-2023-MDPI-Symmetry/" class="article-date">
	  <time datetime="2024-05-14T05:36:20.000Z" itemprop="datePublished">5月 14</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E5%8D%95%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA-Single-object-Tracking/" rel="tag">单目标跟踪 Single-object Tracking</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2024/05/14/paper-2023-MDPI-Symmetry/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/05/14/paper-2023-IEEE-TSMC/">Xiaoyan Jiang, J N Hwang and Z Fang, &#34;A Multiscale Coarse-to-Fine Human Pose Estimation Network With Hard Keypoint Mining&#34; in IEEE Transactions on Systems, Man, and Cybernetics:Systems, March 2024</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>团队负责人姜晓燕老师的论文“A Multiscale Coarse-to-Fine Human Pose Estimation Network With Hard Keypoint Mining” 被SCI期刊IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS接收，祝贺！</p>
<p>Abstract:<br>Current convolution neural network (CNN)-based multiperson pose estimators have achieved great progress, however, they pay no or less attention to “hard” samples, such as occluded keypoints, small and nearly invisible keypoints, and ambiguous keypoints. In this article, we explicitly deal with these “hard” samples by proposing a novel multiscale coarse-to-fine human pose estimation network (HM2PN), which includes two sequential subnetworks: CoarseNet and FineNet. CoarseNet conducts a coarse prediction to locate “simple” keypoints like hands and ankles with a multiscale fusion module, which is integrated with bottleneck, resulting in a novel module called multiscale bottleneck. The new module improves the multiscale representation ability of the network in a fine-grained level, while marginally reducing the computation cost because of group convolution. FineNet further infers “hard” keypoints and refines “simple” keypoints simultaneously with a hard keypoint mining loss. Distinct from the previous works, the proposed loss deals with “hard” keypoints differentially and prevents “simple” keypoints from dominating the computed gradients during training. Experiments on the COCO keypoint benchmark show that our approach achieves superior pose estimation performance compared with other state-of-the-art methods. </p>
<p><strong>Download:</strong> <a target="_blank" rel="noopener" href="https://github.com/sues-vision/C2F-HumanPoseEstimation?tab=readme-ov-file#a-multi-scale-coarse-to-fine-human-pose-estimation-network-with-hard-keypoint-mining">[preprint版本]</a></p>
<p><strong>Keywords:</strong> Hard sample mining, human pose estimation,multiscale</p>
<p><strong>Photos:</strong></p>
<img src="/2024/05/14/paper-2023-IEEE-TSMC/HM2PN.jpg" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2024/05/14/paper-2023-IEEE-TSMC/" class="article-date">
	  <time datetime="2024-05-14T02:25:39.000Z" itemprop="datePublished">5月 14</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Object-Detection/" rel="tag">目标检测 Object Detection</a>, <a class="article-tag-link-link" href="/tags/%E8%A1%8C%E4%BA%BA%E5%88%86%E5%89%B2-Person-Segmentation/" rel="tag">行人分割 Person Segmentation</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2024/05/14/paper-2023-IEEE-TSMC/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/05/11/paper-2023-ictee/">Kunlun Xue, Xiaoyan Jiang, Zhichao Chen“A SLAM Method Based on ORB-SLAM3 Which Mixed GNSS Data” International Conference on Information Technologies and Electrical Engineering</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>团队2021级研究生薛昆仑同学的论文“A SLAM Method Based on ORB-SLAM3 Which Mixed GNSS Data”被“In 6th International Conference on Information Technologies and Electrical Engineering”录用，祝贺！</p>
<p>Abstract:<br>Traditional single-sensor SLAM methods suffer from cumulative drift errors in large-scale outdoor environments, which makes it difficult to have good localization accuracy in practical application scenarios. In this paper, to solve the above problems, we propose a visual inertial system fusion method with global navigation satellite system (GNSS), which transforms GNSS measurements into values in Cartesian coordinate system, and then uses odometry pose information and GNSS information to do nonlinear optimization to eliminate the cumulative drift error within the system, and experiments are carried out on the KITTI raw data, which show that the method proposed in this paper effectively improves the localization accuracy in large-scale outdoor environments. The results show that the method proposed in this paper effectively improves the localization accuracy in outdoor large-scale scenarios, and the localization accuracy on the KITTI dataset is 54% higher than that of ORB-SLAM3 on average.</p>
<p><strong>Download:</strong> <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3640115.3640180">[官方链接]</a></p>
<p><strong>Keywords:</strong>  Simultaneous localization and mapping, Multi-source mixed, Automatic driving, Nonlinear optimization<br><strong>Photos:</strong> </p>
<img src="/2024/05/11/paper-2023-ictee/SLAM1.PNG" class>
<img src="/2024/05/11/paper-2023-ictee/SLAM2.PNG" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2024/05/11/paper-2023-ictee/" class="article-date">
	  <time datetime="2024-05-11T07:52:27.000Z" itemprop="datePublished">5月 11</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E4%B8%89%E7%BB%B4-3D/" rel="tag">三维 3D</a>, <a class="article-tag-link-link" href="/tags/%E5%90%8C%E6%AD%A5%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%9C%B0%E5%9B%BE%E7%BB%98%E5%88%B6-SLAM/" rel="tag">同步定位与地图绘制 SLAM</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2024/05/11/paper-2023-ictee/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/05/07/paper-2023-IEEE/">Wenwen Zheng,Xiaoyan Jiang, Zhijun Fang etc, &#34;TV-Net:A Structure-Level Feature Fusion Network Based on Tensor Voting for Road Crack Segmentation&#34; in IEEE Transactions on Intelligent Transportation Systems, June 2024</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>团队2021级研究生郑雯雯同学的论文“TV-Net: A Structure-Level Feature Fusion NetworkBased on Tensor Voting for RoadCrack Segmentation”被SCI顶刊<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10414408">《Institute-of-Electrical-and-Electronics-Engineers》</a> 录用，祝贺！</p>
<p>Abstract:<br>Pavement cracks are a common and significant problem for intelligent pavement maintainment. However, the features extracted in pavement images are often texture-less, and noise interference can be high. Segmentation using traditional convolutional neural network training can lose feature information when the network depth goes larger, which makes accurate prediction a challenging topic. To address these issues, we propose a new approach that features an enhanced tensor voting module and a customized pixel-level pavement crack segmentation network structure, called TV-Net. We optimize the tensor voting framework and find the relationship between tensor scale factors and crack distributions. A tensor voting fusion module is introduced to enhance feature maps by incorporating significant domain maps generated by tensor voting. Additionally, we propose a structural consistency loss function to improve segmentation accuracy and ensure consistency with the structural characteristics of the cracks obtained through tensor voting. The sufficient experimental analysis demonstrates that our method outperforms existing mainstream pixel-level segmentation networks on the same road crack dataset. Our proposed TV-Net has an excellent performance in avoiding noise interference and strengthening the structure of the fracture site of pavement cracks. </p>
<p><strong>Download:</strong> <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10414408">[官方链接]</a> <a target="_blank" rel="noopener" href="https://github.com/sues-vision/TV-Net">[preprint版本]</a></p>
<p><strong>Keywords:</strong> Crack detection  convolutional neural network tensor voting  U-Net</p>
<p><strong>Photos:</strong> </p>
<img src="/2024/05/07/paper-2023-IEEE/TV.PNG" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2024/05/07/paper-2023-IEEE/" class="article-date">
	  <time datetime="2024-05-07T07:51:43.000Z" itemprop="datePublished">5月 7</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E8%A3%82%E7%BC%9D%E6%A3%80%E6%B5%8B-Crack-Detection/" rel="tag">裂缝检测 Crack Detection</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2024/05/07/paper-2023-IEEE/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
  </div>

  
    
    <nav class="bar bar-footer clearfix" data-stick-bottom>
        <div class="bar-inner">
        <ul class="pager pull-left">
            
            <li class="prev disabled">
                <a href="javascript:;">
                    <i class="icon icon-angle-left"></i>
                    上一页
                </a>
            </li>
            
            
            <li class="next">
                <a href="/page/2/">
                    下一页
                    <i class="icon icon-angle-right"></i>
                </a>
            </li>
            
        </ul>
            <div class="total-article bar-right">Page 1 of 4</div>
        </div>
    </nav>
    
 
</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   









</body>
</html>