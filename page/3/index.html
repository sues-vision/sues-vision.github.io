<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Hexo</title>
  <meta name="description" content="计算机视觉，人工智能">
<meta property="og:type" content="website">
<meta property="og:title" content="Multi-Dimensional Computer Vision Team">
<meta property="og:url" content="http://sues-vision.github.io/page/3/index.html">
<meta property="og:site_name" content="Multi-Dimensional Computer Vision Team">
<meta property="og:description" content="计算机视觉，人工智能">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Atiuo">
<meta name="twitter:card" content="summary">
  <!-- Canonical links -->
  <link rel="canonical" href="http://sues-vision.github.io/page/3/index.html">
  
    <link rel="alternate" href="/atom.xml" title="Multi-Dimensional Computer Vision Team" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/1.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  
  
  
<meta name="generator" content="Hexo 5.3.0"></head>


<body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/sues-vision" target="_blank">
          <img class="img-circle img-rotate" src="/img/avatar.png" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">多维度计算机视觉团队</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Multi-Dimensional Computer Vision Team</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shanghai, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-papers">
          <a href="/2017/12/31/03-paperlist">
            
            <span class="menu-title">论文</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/2017/12/31/02-projects">
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-reward">
          <a href="/reward">
            
            <span class="menu-title">获奖</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-patents">
          <a href="/Patents">
            
            <span class="menu-title">专利</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-graduate">
          <a href="/graduate">
            
            <span class="menu-title">毕业生去向</span>
          </a>
        </li>
        
      </ul>
      
    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/%E4%B8%89%E7%BB%B4-3D/" style="font-size: 13.75px;">三维 3D</a> <a href="/tags/%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB-Action-Recognition/" style="font-size: 13px;">动作识别 Action Recognition</a> <a href="/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F-Medical-Image/" style="font-size: 13.25px;">医学图像 Medical Image</a> <a href="/tags/%E5%8D%95%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA-Single-object-Tracking/" style="font-size: 13px;">单目标跟踪 Single-object Tracking</a> <a href="/tags/%E5%90%8C%E6%AD%A5%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%9C%B0%E5%9B%BE%E7%BB%98%E5%88%B6-SLAM/" style="font-size: 13.25px;">同步定位与地图绘制 SLAM</a> <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-GNN/" style="font-size: 13px;">图神经网络 GNN</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81-CLIP/" style="font-size: 13px;">多模态 CLIP</a> <a href="/tags/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA-MOT/" style="font-size: 13.25px;">多目标跟踪 MOT</a> <a href="/tags/%E5%AD%A6%E6%9C%AF%E4%BA%A4%E6%B5%81-Academic-Activities/" style="font-size: 13px;">学术交流 Academic Activities</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88-Data-Fusion/" style="font-size: 13.25px;">数据融合 Data Fusion</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Unsupervised-Learning/" style="font-size: 13px;">无监督学习 Unsupervised Learning</a> <a href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Attention/" style="font-size: 13.75px;">注意力机制 Attention</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Object-Detection/" style="font-size: 13.5px;">目标检测 Object Detection</a> <a href="/tags/%E8%87%AA%E4%B8%BB%E8%BF%90%E5%8A%A8-ego-motion/" style="font-size: 13px;">自主运动 ego-motion</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6-Automatic-Driving/" style="font-size: 13px;">自动驾驶 Automatic Driving</a> <a href="/tags/%E8%A1%8C%E4%BA%BA%E5%88%86%E5%89%B2-Person-Segmentation/" style="font-size: 13.25px;">行人分割 Person Segmentation</a> <a href="/tags/%E8%A1%8C%E4%BA%BA%E9%87%8D%E8%AF%86%E5%88%AB-Person-re-identification/" style="font-size: 13.5px;">行人重识别 Person re-identification</a> <a href="/tags/%E8%A3%82%E7%BC%9D%E6%A3%80%E6%B5%8B-Crack-Detection/" style="font-size: 13px;">裂缝检测 Crack Detection</a> <a href="/tags/%E8%AE%BA%E6%96%87-Article/" style="font-size: 14px;">论文 Article</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">五月 2024</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">四月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">3</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/14/paper-2023-MDPI-Symmetry/" class="title">Fan L，Chen W，Jiang X Cross-Correlation Fusion Graph Convolution-Based Object Tracking，*Symmetry* 2023</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-14T05:36:20.000Z" itemprop="datePublished">2024-05-14</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/14/paper-2023-IEEE-TSMC/" class="title">Xiaoyan Jiang, J N Hwang and Z Fang, &#34;A Multiscale Coarse-to-Fine Human Pose Estimation Network With Hard Keypoint Mining&#34; in IEEE Transactions on Systems, Man, and Cybernetics:Systems, March 2024</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-14T02:25:39.000Z" itemprop="datePublished">2024-05-14</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/11/paper-2023-ictee/" class="title">Kunlun Xue, Xiaoyan Jiang, Zhichao Chen“A SLAM Method Based on ORB-SLAM3 Which Mixed GNSS Data” International Conference on Information Technologies and Electrical Engineering</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-11T07:52:27.000Z" itemprop="datePublished">2024-05-11</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/07/paper-2023-IEEE/" class="title">Wenwen Zheng,Xiaoyan Jiang, Zhijun Fang etc, &#34;TV-Net:A Structure-Level Feature Fusion Network Based on Tensor Voting for Road Crack Segmentation&#34; in IEEE Transactions on Intelligent Transportation Systems, June 2024</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-07T07:51:43.000Z" itemprop="datePublished">2024-05-07</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
              </p>
              <p class="item-title">
                <a href="/2024/05/06/paper-2023-PR/" class="title">Baihong Han, Xiaoyan Jiang, Zhijun Fang, Hamido Fujita, Yongbin Gao,F-SCP:An automatic prompt generation method for specific classes based on visual language pre-training models,*Pattern Recognition*,2024</a>
              </p>
              <p class="item-date">
                <time datetime="2024-05-06T09:43:16.000Z" itemprop="datePublished">2024-05-06</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  <main class="main" role="main">
  
  <div class="content article-list">
    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/02/01/paper-2021-KBS/">Kaiying Zhu, Xiaoyan Jiang, Zhijun Fang, Yongbin Gao etc, Jenq-Neng Hwang,Photometric transfer for direct visual odometry,Knowledge-Based Systems,2021</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>团队2018级研究生朱凯赢同学的论文“Photometric transfer for direct visual odometry”被SCI期刊<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/journal/knowledge-based-systems">《Knowledge-Based Systems》</a> 录用，祝贺！</p>
<p>Abstract:<br>Due to efficient photometric information utilization, direct visual odometry (DVO) is getting widely used to estimate the ego-motion of moving cameras as well as map the environment from videos simultaneously, especially in challenging weak-texture scenarios. However, DVO suffers from brightness discrepancies since it directly utilizes intensity patterns of pixels to register frames for camera pose estimation. Most existing brightness transfer methods build a fixed transfer function which is inappropriate for successive and inconsistent brightness changes in practice. To overcome this problem, we propose a Photometric Transfer Net (PTNet) which is trained to pixel-wisely remove brightness discrepancies between two frames without ruining the context information. Photometric consistency in DVO is obtained by adjusting the source frame according to the reference frame. Since no dataset is available for training the photometric transfer model, we augment the EuRoC dataset by generating a certain number of frames with different brightness levels for each original frame by a nonlinear transformation. Afterwards, required training data containing various brightness changes and scene movements along with ground truth can be collected from the extended sequences. Evaluations on both real-world and synthetic datasets demonstrate the effectiveness of the proposed model. Assessment on an unseen dataset with fixed model parameters trained on another dataset proves the generalization ability of the model. Furthermore, we embed the model into DVO to preprocess input data with brightness discrepancies. Experimental results show that PTNet-based DVO achieves more robust initialization and accurate pose estimation than the original one.</p>
<p><strong>Download:</strong> <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0950705120308005">[官方链接]</a> <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1BBUuFnLOW4c6kY5ab3GwTo_efYkYi47F/view?usp=sharing">[preprint版本]</a></p>
<p><strong>Keywords:</strong> Photometric transfer, Direct visual odometry, Data augmentation, Brightness discrepancy, Deep learning.</p>
<p><strong>Photos:</strong></p>
<img src="/2021/02/01/paper-2021-KBS/fig2.png" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2021/02/01/paper-2021-KBS/" class="article-date">
	  <time datetime="2021-02-01T07:05:22.000Z" itemprop="datePublished">2月 1</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E4%B8%89%E7%BB%B4-3D/" rel="tag">三维 3D</a>, <a class="article-tag-link-link" href="/tags/%E5%90%8C%E6%AD%A5%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%9C%B0%E5%9B%BE%E7%BB%98%E5%88%B6-SLAM/" rel="tag">同步定位与地图绘制 SLAM</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2021/02/01/paper-2021-KBS/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/12/31/paper-2020-MP/">Lingyu Ji, Xiaoyan Jiang, Yongbin Gao, Zhijun Fang,“ADR‐Net:Context extraction network based on M‐Net for medical image segmentation” Medical Physics</a>
    </h1>
  

  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2020/12/31/paper-2020-MP/" class="article-date">
	  <time datetime="2020-12-31T07:45:40.000Z" itemprop="datePublished">12月 31</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F-Medical-Image/" rel="tag">医学图像 Medical Image</a>, <a class="article-tag-link-link" href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Attention/" rel="tag">注意力机制 Attention</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2020/12/31/paper-2020-MP/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/01/paper-2020-KBS/">Yang Li, Xiaoyan Jiang, Jenq-Neng Hwang,Effective person re-identification by self-attention model guided feature learning,Knowledge-Based Systems</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>团队2017级研究生黎阳同学的论文“Effective Person Re-identiﬁcation by Self-Attention Model Guided Feature Learning”被SCI期刊<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/journal/knowledge-based-systems">《Knowledge-Based Systems》</a> 录用，祝贺！</p>
<p>Abstract:<br>Person re-identification (re-ID), of which the goal is to recognize person identities of images captured by non-overlapping cameras, is a challenging topic in computer vision. Most existing person re-ID methods conduct directly on detected objects, which ignore the space misalignment caused by detectors, human pose variation, and occlusion problems. To tackle the above mentioned difficulties, we propose a self-attention model guided deep convolutional neural network(DCNN) to learn robust features from image shots. Kernels of the self-attention model evaluate weights for the importance of different person regions. To solve the local feature dependence problem of feature extraction, the non-local feature map generated by the self-attention model is fused with the original feature map generated from the resnet-50. Furthermore, the loss function considers both the cross-entropy loss and the triplet loss in the training process, which enables the network to capture common characteristics within the same individuals and significant differences between distinct persons. Extensive experiments and comparative evaluations show that our proposed strategy outperforms most of the state-of-the-art methods on standard datasets: Market-1501, DukeMTMC-reID, and CUHK03.</p>
<p><strong>Download:</strong> <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0950705119303077">[官方链接]</a> <a href="(https://github.com/sues-vision/pre-print-papers">[preprint版本]</a></p>
<p><strong>Keywords:</strong> Personre-identification, Feature extraction, Self-attention, Cross-entropy loss, Triplet loss.</p>
<p><strong>Photos:</strong></p>
<img src="/2020/03/01/paper-2020-KBS/fig2.png" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2020/03/01/paper-2020-KBS/" class="article-date">
	  <time datetime="2020-03-01T07:05:22.000Z" itemprop="datePublished">3月 1</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-Attention/" rel="tag">注意力机制 Attention</a>, <a class="article-tag-link-link" href="/tags/%E8%A1%8C%E4%BA%BA%E9%87%8D%E8%AF%86%E5%88%AB-Person-re-identification/" rel="tag">行人重识别 Person re-identification</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2020/03/01/paper-2020-KBS/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/31/academicActivities-2019/">学术交流</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>2019年9月21日，应AEIC组委会邀请，团队负责人姜晓燕博士前往大连参加International Conference on Frontiers Technology of Information and Computer会议，并做主旨报告。</p>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2020/01/31/academicActivities-2019/" class="article-date">
	  <time datetime="2020-01-31T07:45:35.000Z" itemprop="datePublished">1月 31</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E5%AD%A6%E6%9C%AF%E4%BA%A4%E6%B5%81-Academic-Activities/" rel="tag">学术交流 Academic Activities</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2020/01/31/academicActivities-2019/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
      <article class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/12/31/paper-2019-Access/">Xiaoyan Jiang and Yongbin Gao and Zhijun Fang and Bo Huang“An End-to-End Human Segmentation by Region Proposed Fully Convolutional Network” IEEE Access</a>
    </h1>
  

  </div>
  
  <div class="article-entry text-muted" itemprop="description">
    <p>团队负责人姜晓燕老师的论文“An End-to-End Human Segmentation by Region Proposed Fully Convolutional Network” 被SCI期刊IEEE Access接收，祝贺！</p>
<p>Abstract:<br>Person segmentation in images has various applications, for example, smart home, human-computer interaction, and scene perception for self-driving cars, which are a key feature of the Internet of Things. Due to limitations in performance, such as accuracy and runtime, most traditional methods do not fulfill the practical requirements. Deep learning-based modern segmentation systems become prevalent. Fully convolutional network (FCN), as a classic image semantic segmentation method, directly optimizes the semantic map from the original image in a pixel-wise manner without using pixel-correlations or global object information. In this paper, we propose an efficient end-to-end person segmentation network structure fusing the person detection network with the FCN. The person detection network estimates the region of interest of persons and enforces the segmentation network to focus on the optimization of person segmentation. The loss function of the proposed network considers both the segmentation error and the detection bias error. In addition, the lightweight design of the detection network that optimizes only person bounding-box coordinates enables real-time person detection. The experimental comparison and analysis of several different networks on several datasets show the effectiveness of the proposed fusion strategy. The approach shows a promising practical application potential by fast running time and high segmentation accuracy.</p>
<p><strong>Download:</strong> <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/8611439">[官方链接]</a></p>
<p><strong>Keywords:</strong> Person segmentation, fully convolutional network, object detection network, internet of things.</p>
<p><strong>Photos:</strong></p>
<img src="/2019/12/31/paper-2019-Access/fig4.png" class>
  </div>
  
  <p class="article-meta">
    <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2019/12/31/paper-2019-Access/" class="article-date">
	  <time datetime="2019-12-31T07:45:40.000Z" itemprop="datePublished">12月 31</time>
	</a>
</span>
    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/AcademicActivities/">AcademicActivities</a>
  </span>

    
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Object-Detection/" rel="tag">目标检测 Object Detection</a>, <a class="article-tag-link-link" href="/tags/%E8%A1%8C%E4%BA%BA%E5%88%86%E5%89%B2-Person-Segmentation/" rel="tag">行人分割 Person Segmentation</a>, <a class="article-tag-link-link" href="/tags/%E8%AE%BA%E6%96%87-Article/" rel="tag">论文 Article</a>
  </span>


    <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2019/12/31/paper-2019-Access/#comments" class="article-comment-link">评论</a></span>
    
  </p>
</article>

    
  </div>

  
    
    <nav class="bar bar-footer clearfix" data-stick-bottom>
        <div class="bar-inner">
        <ul class="pager pull-left">
            
            <li class="prev">
                <a href="/page/2/">
                    <i class="icon icon-angle-left"></i>
                    上一页
                </a>
            </li>
            
            
            <li class="next">
                <a href="/page/4/">
                    下一页
                    <i class="icon icon-angle-right"></i>
                </a>
            </li>
            
        </ul>
            <div class="total-article bar-right">Page 3 of 4</div>
        </div>
    </nav>
    
 
</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   









</body>
</html>